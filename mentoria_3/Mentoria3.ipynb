{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TercerMentoria.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-nQGofxOA8S"
      },
      "source": [
        "#Bienvenidos a la mentoría: \n",
        "##\"Ciencia de datos aplicada al estudio de la Obesidad y otras enfermedades crónicas en Córdoba.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN5r00zhhL5d"
      },
      "source": [
        "##### Como primer objetivo proponemos acercarnos a la temática propuesta presentando una breve introducción de la misma y sus posibles determinantes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5gkuPZ4OHbp"
      },
      "source": [
        "##Descripción del problema\n",
        "La obesidad es una enfermedad crónica multicausal de alta prevalencia en el mundo y Argentina. La misma se encuentra en constante aumento y en Córdoba son más del 50% las personas que presentan exceso de peso, y un 25% del total obesidad. Si bien se piensa que los principales factores que influyen en su desarrollo, son un nivel de actividad física inadecuado, el sedentarismo y una alimentación poco saludable, pueden existir otros determinantes de esta condición que deban ser considerados. Sin embargo, muchas veces es difícil contar con todos estos datos y analizarlos de manera conjunta  o considerando su efecto sinérgico.\n",
        "Por otra parte, al conocer los aspectos que más influyen en la ocurrencia de esta enfermedad se podría abordar de manera integral y ofrecer a la población información, realizar recomendaciones y utilizar estos resultados para implementar políticas públicas para enfrentar la pandemia de la obesidad.\n",
        "Así, en esta mentoría poneo a dispoición un dataset que tiene una numerosa variedad de features las cuales permitirán poder seleccionar aquellos que sean los mejores predictores para la enfermedad. También identificar patrones de alimentación y subgrupos de sujetos que compartan ciertas características, y de esta forma descubrir nuevos insights para desarrollar.   \n",
        "Además, resulta interesante desarrollar metodologías para analizar y describir este problema, las que pueden ser replicadas en otros de las Ciencias de la salud y en el que se utilicen principalmente las herramientas que la Ciencia de Datos provee.\n",
        "Esperamos que en esta mentoría puedas desarrollar y aplicar todas las herramientas y skills aprendidas durante el cursado de la diplomatura. Te proponemos objetivos específicos para la resolución de cada práctico poniendo en juego tus conocimientos y creatividad, y quién te dice encontras tu lado Abby Sciuto/John Snow. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzsI1LyHONx4"
      },
      "source": [
        "##Motivación\n",
        "❖\t¿Cuáles son las principales características de la población de Córdoba en cuanto a sus determinantes bio-socio-económicos?\n",
        "\n",
        "❖\t¿Es la obesidad una enfermedad que depende meramente de la alimentación de los sujetos?\n",
        "\n",
        "❖\t¿Cuáles son los factores alimentarios que promueven el desarrollo de la enfermedad?¿Y cuáles son aquellos que protegen?\n",
        "\n",
        "❖\t¿Se encuentra la obesidad asociada a la enfermedad cardiovascular?¿y al cáncer?\n",
        "\n",
        "❖\t¿Qué variables ayudarían a predecir el estado nutricional de un sujeto de la población de Córdoba?\n",
        "\n",
        "❖\t¿Cuáles son las características más visibles de los grupos según su estado nutricional?¿Existen características comunes que nos permitan predecir el estado nutricional que tendrá una persona?\n",
        "\n",
        "❖\t¿Existe algún patrón alimentario característico por grupos según la presencia o no de obesidad?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFkXu9PjWgtf"
      },
      "source": [
        "# **Práctico N°3**           **Introducción al aprendizaje automático**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6dsCC0tg7aT"
      },
      "source": [
        "## Objetivo y alcance\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM9VAmMT4WiY"
      },
      "source": [
        "Para esta materia el objetivo es poder hacer un primer acercamiento a un proceso de aprendizaje automático,Nos enfocaremos en el en el proceso de: selección de un modelo, ajuste de hiperparámetros y evaluación,regulador, métricas, similar a lo que hicieron en el segundo laboratorio de esta materia.\n",
        "En este laboratorio no se espera que se encuentre el mejor modelo con sus mejores parámetros, sino que se logre la buena práctica de realizar los pasos necesarios en un proceso de aprendizaje automático, desde la división del dataset hasta la evaluación del modelo. Para realizar el práctico vamos a utilizar el dataset generado en la materia anterior. \n",
        "\n",
        "\n",
        "### **La necesidad es la siguiente:**\n",
        "\n",
        "1.   Poder predecir de forma automática la presencia de obesidad (todos los grados) en toda la población.\n",
        "2.   Poder predecir de forma automática la presencia de obesidad en mujeres (grupo 1) y todos los hombres (grupo 2).\n",
        "3. Poder determinar cuales son las variables que son consideradas factores de riesgo para presentar obesidad, tanto para toda la población como discriminando por sexos.\n",
        "\n",
        "### **Para ello se debe:**\n",
        "\n",
        "*   Crear una variable que responda a la demanda (obesidad = IMC > 29.9)\n",
        "*  Cargar los datos, separando del dataset la etiqueta a predecir.\n",
        "* Dividir el dataset en el conjunto de entrenamiento y conjunto de test\n",
        "*   Analizar y justificar que features se utilizarán para lograr la mejor predicción.\n",
        "*   Elegir dos modelos de clasificación (uno por cada requerimiento). Los que Uds. se sientan más cómodos, pero también justificando conceptualmente la elección de la función de regularización.\n",
        "*   Entrenar y evaluar los modelos, fijando la semilla aleatoria para hacer repetible el experimento.\n",
        "*   En cuanto a los hiper-parámetros:\n",
        "\n",
        "        1.   Probar primero con los default y elegir alguna/s métrica/s para reportar los resultados. \n",
        "        2.   Luego usar grid-search y 5-fold cross-validation para explorar muchas combinaciones posibles de valores, reportando  accuracy promedio y varianza para todas las configuraciones.\n",
        "\n",
        "*   Para la mejor configuración encontrada, evaluar sobre el conjunto de entrenamiento y sobre el conjunto de evaluación, reportando:\n",
        "        *   Accuracy\n",
        "        *   Precision\n",
        "        *   Recall\n",
        "        *   F1\n",
        "        *   Matriz de confusión\n",
        "\n",
        "### Se evaluarán los siguientes aspectos:\n",
        "  ***1-*** Que se apliquen los conceptos vistos con los profes en el teórico y en el práctico.\n",
        "\n",
        "  ***2-*** Que el entregable no sea solo la notebook. El informe debe tener un mensaje claro y debe presentarse en un formato legible para cualquier tipo de stakeholder.\n",
        "\n",
        "  ***3-*** Capacidad de análisis.\n",
        "\n",
        "  ***4-*** Criterio para elegir que solución aplicar en cada caso y con qué método implementarla.\n",
        "\n",
        "\n",
        "  \n",
        "## Deadline pautado para la entrega: Lunes 16/08/2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2uW9UYDWspO"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## Estructura del informe\n",
        "El informe debe estar en un formato que no sea Jupyter Notebook, por ejemplo .html, .pdf, .md. El objetivo es poder redactar y justificar las conclusiones obtenidas a partir de las preguntas disparadoras, utilizando material gráfico y/o interactivo como soporte para complementar las ideas. \n",
        "Además, se debe presentar o enviar la notebook en donde se trabajó (jupyter notebook, colab notebook, etc).  \n",
        "\n",
        "###Se evaluarán los siguientes aspectos:\n",
        "Que se apliquen los conceptos vistos en el dictado de la materia.\n",
        "\n",
        "El informe debe tener un mensaje claro y debe presentarse en un formato legible para cualquier tipo de stakeholder.\n",
        "\n",
        "Que los cálculos estadísticos sean utilizados solo como herramientas para responder a las consignas.\n",
        "\n",
        "Indicar el criterio aplicado al momento de elegir las variables a analizar.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzJ4l-qbpY1x",
        "outputId": "536ccd05-aa65-435d-ecf6-3aabd0425e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy             as np\n",
        "import pandas            as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn \n",
        "\n",
        "# Metrics \n",
        "from sklearn.metrics         import accuracy_score\n",
        "from sklearn.metrics         import f1_score\n",
        "from sklearn.metrics         import precision_score\n",
        "from sklearn.metrics         import recall_score\n",
        "from sklearn.metrics         import confusion_matrix\n",
        "\n",
        "# Models selections\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.linear_model    import SGDClassifier\n",
        "from sklearn.tree            import DecisionTreeClassifier\n",
        "from sklearn.linear_model    import LogisticRegression\n",
        "from sklearn.neighbors       import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14jvHyKOTn4Z"
      },
      "source": [
        "def print_model_metrics(y_test, y_pred):\n",
        "    accuracy    = accuracy_score   (y_test, y_pred) \n",
        "    precision   = precision_score  (y_test, y_pred)\n",
        "    recall      = recall_score     (y_test, y_pred)\n",
        "    f1          = f1_score         (y_test, y_pred)\n",
        "    confusion   = confusion_matrix (y_test, y_pred)\n",
        "\n",
        "    metrics_map = { 'Accuracy'         : accuracy   ,\n",
        "                    'Precision'        : precision  ,\n",
        "                    'Recall'           : recall     , \n",
        "                    'f1_score'         : f1         \n",
        "                  }\n",
        "    \n",
        "    for metric in metrics_map:\n",
        "        print(metric, round(metrics_map[metric],2))\n",
        "    \n",
        "    print(confusion)\n",
        "    print('\\n True Negatives '  + str(confusion[0][0]))\n",
        "    print('\\n False Negatives ' + str(confusion[1][0]))\n",
        "    print('\\n True Positives '  + str(confusion[1][1]))\n",
        "    print('\\n False Positives ' + str(confusion[0][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsRI0p8QQSQw",
        "outputId": "29c2f423-9da0-43af-b4a3-116292e0e085",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from   google.colab      import files\n",
        "encuestas = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c2a87b52-d9cc-4c19-9660-58ff58e4674c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c2a87b52-d9cc-4c19-9660-58ff58e4674c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cured_data_obesity.csv to cured_data_obesity.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbXps2zEeLXC"
      },
      "source": [
        "obedf    = pd.read_csv('cured_data_obesity.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4kTIK6apwXl"
      },
      "source": [
        "# Eliminamos posibles valores NaN\n",
        "obedf = obedf[obedf['IMC'].isna() == False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjkVUfhVnFs5"
      },
      "source": [
        "# Creamos una variable target \n",
        "obedf['TARGET'] = obedf['IMC'].apply(lambda x: 0 if x <= 29.9 else 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuyCvRQe9v3s"
      },
      "source": [
        "# Seleccionamos los atributos en base a su relacion con la variable IMC.\n",
        "obedf_mujeres = obedf[obedf.sexo == 0]\n",
        "obedf_hombres = obedf[obedf.sexo == 1]\n",
        "\n",
        "for atribute in obedf.columns[5:len(obedf.columns) - 6]:\n",
        "  ax1 = plt.subplot2grid((1,3), (0,0), rowspan=1, colspan=1)\n",
        "  ax2 = plt.subplot2grid((1,3), (0,1), rowspan=1, colspan=1)\n",
        "  ax3 = plt.subplot2grid((1,3), (0,2), rowspan=1, colspan=1)\n",
        "\n",
        "  seaborn.scatterplot(data=obedf        , x=atribute, y='IMC', ax=ax1)\n",
        "  seaborn.scatterplot(data=obedf_mujeres, x=atribute, y='IMC', ax=ax2)\n",
        "  seaborn.scatterplot(data=obedf_hombres, x=atribute, y='IMC', ax=ax3)\n",
        "  \n",
        "  plt.show()\n",
        "  input()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uywHGtok-FmQ"
      },
      "source": [
        "# Nos quedamos con estos atributos para entrenar el modelo.\n",
        "atributos_todos   = ['ic', 'dbt', 'tipo1', 'tipo2', 'tratadbt', 'mets', 'imagen_percibida', 'cc', 'ten2max', 'ten2min', 'vis', 'frus', 'frud', 'leg', 'past', 'azuc', 'agua', 'cpre']\n",
        "atributos_mujeres = ['dbt','tipo1','tipo2','tratadbt','mets','imagen_percibida','cc','ten2max','ten2min','vis','frus','frud','leg','agua','cpre'] \n",
        "atributos_hombres = ['ec','anteher','dbt','tipo1','tipo2','tratadbt','tumben','mets','imagen_percibida','cc','ten2max','ten2min','vis' ,'fvis','fibfrua','frus','frud','leg','past','azuc','agua','cpre']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNuvUq3q-9TW"
      },
      "source": [
        "# Nos quedamos con un dataset solo con target y estos atributos\n",
        "obedf         = obedf[atributos_todos+['TARGET']]\n",
        "obedf_mujeres = obedf_mujeres[atributos_mujeres+['TARGET']]\n",
        "obedf_hombres = obedf_hombres[atributos_hombres+['TARGET']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0yW7yQbB3Ng",
        "outputId": "79372a46-9425-41dd-93f9-063fd23ad5da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Queremos ver cuantos datos NaN hay en los atributos elegidos, para ver si al\n",
        "# eliminarlos no alteramos las relacion entre las clases 0 y 1.\n",
        "\n",
        "for atributo in atributos_todos:\n",
        "  print (atributo + '\\t' + str(obedf[atributo].isna().sum()))\n",
        "\n",
        "print (obedf[obedf.mets.isna()].TARGET.value_counts())\n",
        "print (obedf[obedf.Gcarhue.isna()].TARGET.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cc\t0\n",
            "ten2max\t0\n",
            "ten2min\t0\n",
            "mets\t362\n",
            "dbt\t1\n",
            "tipo2\t1\n",
            "tratadbt\t1\n",
            "act\t0\n",
            "imagen_percibida\t0\n",
            "ffs2\t1\n",
            "vis\t0\n",
            "Gcarhue\t74\n",
            "pan\t0\n",
            "past\t0\n",
            "azuc\t0\n",
            "mant\t0\n",
            "agua\t0\n",
            "0    333\n",
            "1     29\n",
            "Name: TARGET, dtype: int64\n",
            "0    64\n",
            "1    10\n",
            "Name: TARGET, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft5FgWmSDX0Z"
      },
      "source": [
        "# Eliminamos las filas con NaN en alguno de sus atributos.\n",
        "\n",
        "for atributo in atributos_todos:\n",
        "  obedf = obedf[obedf[atributo].isna() == False]\n",
        "\n",
        "for atributo in atributos_mujeres:\n",
        "  obedf_mujeres = obedf_mujeres[obedf_mujeres[atributo].isna() == False]\n",
        "\n",
        "for atributo in atributos_hombres:\n",
        "  obedf_hombres = obedf_hombres[obedf_hombres[atributo].isna() == False]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPRaZvucEGjj"
      },
      "source": [
        "# Dividir los datos, con stratify para mantener la relacion.\n",
        "X_todos, y_todos = obedf.iloc[:, :-1], obedf.TARGET\n",
        "X_todos_train, X_todos_test, y_todos_train, y_todos_test = train_test_split(X_todos, y_todos, test_size=0.2, random_state=0, stratify=y_todos)\n",
        "\n",
        "X_mujeres, y_mujeres = obedf_mujeres.iloc[:, :-1], obedf_mujeres.TARGET\n",
        "X_mujeres_train, X_mujeres_test, y_mujeres_train, y_mujeres_test = train_test_split(X_mujeres, y_mujeres, test_size=0.2, random_state=0, stratify=y_mujeres)\n",
        "\n",
        "X_hombres, y_hombres = obedf_hombres.iloc[:, :-1], obedf_hombres.TARGET\n",
        "X_hombres_train, X_hombres_test, y_hombres_train, y_hombres_test = train_test_split(X_hombres, y_hombres, test_size=0.2, random_state=0, stratify=y_hombres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmKdYmRFwmhh",
        "outputId": "d9b1f69b-cbfa-48fe-f529-97ad23a63a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Primero corremos entrenamos para el grupo de todos\n",
        "classifier   = SGDClassifier(random_state = 0)\n",
        "classifier.fit(X_todos_train, y_todos_train)\n",
        "y_todos_pred_train = classifier.predict(X_todos_train)\n",
        "y_todos_pred_test  = classifier.predict(X_todos_test)\n",
        "\n",
        "print('### Metricas de entrenamiento SDGC###')\n",
        "print_model_metrics(y_todos_train, y_todos_pred_train)\n",
        "print('\\n### Metricas de test SDGC ###')\n",
        "print_model_metrics(y_todos_test, y_todos_pred_test)\n",
        "\n",
        "classifier   = DecisionTreeClassifier(random_state = 0)\n",
        "classifier.fit(X_todos_train, y_todos_train)\n",
        "y_todos_pred_train = classifier.predict(X_todos_train)\n",
        "y_todos_pred_test  = classifier.predict(X_todos_test)\n",
        "\n",
        "print('### Metricas de entrenamiento Tree ###\\n')\n",
        "print_model_metrics(y_todos_train, y_todos_pred_train)\n",
        "print('\\n### Metricas de test ### Tree \\n')\n",
        "print_model_metrics(y_todos_test, y_todos_pred_test)\n",
        "\n",
        "print(classifier.tree_.max_depth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### Metricas de entrenamiento SDGC###\n",
            "Accuracy 0.84\n",
            "Precision 0.38\n",
            "Recall 0.12\n",
            "f1_score 0.18\n",
            "[[2491   92]\n",
            " [ 411   57]]\n",
            "\n",
            " True Negatives 2491\n",
            "\n",
            " False Negatives 411\n",
            "\n",
            " True Positives 57\n",
            "\n",
            " False Positives 92\n",
            "\n",
            "### Metricas de test SDGC ###\n",
            "Accuracy 0.84\n",
            "Precision 0.42\n",
            "Recall 0.16\n",
            "f1_score 0.23\n",
            "[[620  26]\n",
            " [ 98  19]]\n",
            "\n",
            " True Negatives 620\n",
            "\n",
            " False Negatives 98\n",
            "\n",
            " True Positives 19\n",
            "\n",
            " False Positives 26\n",
            "### Metricas de entrenamiento Tree ###\n",
            "\n",
            "Accuracy 1.0\n",
            "Precision 1.0\n",
            "Recall 1.0\n",
            "f1_score 1.0\n",
            "[[2583    0]\n",
            " [   0  468]]\n",
            "\n",
            " True Negatives 2583\n",
            "\n",
            " False Negatives 0\n",
            "\n",
            " True Positives 468\n",
            "\n",
            " False Positives 0\n",
            "\n",
            "### Metricas de test ### Tree \n",
            "\n",
            "Accuracy 0.87\n",
            "Precision 0.56\n",
            "Recall 0.6\n",
            "f1_score 0.58\n",
            "[[592  54]\n",
            " [ 47  70]]\n",
            "\n",
            " True Negatives 592\n",
            "\n",
            " False Negatives 47\n",
            "\n",
            " True Positives 70\n",
            "\n",
            " False Positives 54\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9mlniI_hJNC",
        "outputId": "1601c3db-c56a-476c-be2a-3f562c43246a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Ahora buscamos el mejor modelo para el descenso por gradiente y el conjunto de datos totales.\n",
        "param_map = { 'loss'          : ['hinge','log','squared_hinge'],\n",
        "              'penalty'       : ['l2','l1','elasticnet'],\n",
        "              'learning_rate' : ['optimal','adaptive','invscaling'],\n",
        "              'eta0'          : [0.1],\n",
        "              'max_iter'      : [20000,30000],\n",
        "              'alpha'         : [0.0001, 0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "classifier   = SGDClassifier(random_state = 0)\n",
        "\n",
        "grid_search = GridSearchCV(classifier, param_map, scoring = 'accuracy', cv= None) # By default it uses 5 fold validation)\n",
        "grid_search.fit(X_todos_train, y_todos_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(best_model)\n",
        "\n",
        "best_model.fit(X_todos_train, y_todos_train)\n",
        "y_todos_pred = best_model.predict(X_todos_test)\n",
        "print_model_metrics(y_todos_test, y_todos_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
            "              early_stopping=False, epsilon=0.1, eta0=0.1, fit_intercept=True,\n",
            "              l1_ratio=0.15, learning_rate='adaptive', loss='hinge',\n",
            "              max_iter=20000, n_iter_no_change=5, n_jobs=None,\n",
            "              penalty='elasticnet', power_t=0.5, random_state=0, shuffle=True,\n",
            "              tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "Accuracy 0.91\n",
            "Precision 0.7\n",
            "Recall 0.68\n",
            "f1_score 0.69\n",
            "[[612  34]\n",
            " [ 38  79]]\n",
            "\n",
            " True Negatives 612\n",
            "\n",
            " False Negatives 38\n",
            "\n",
            " True Positives 79\n",
            "\n",
            " False Positives 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ2tlgvxhRjU",
        "outputId": "e005d4c2-ae8d-40e3-9dc1-4a7d8440937c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "param_map = { 'criterion'        : ['gini','entropy'],\n",
        "              'splitter'         : ['best','random'],\n",
        "              'max_depth'        : list(range(2, 20, 1)) + [None],\n",
        "              'min_samples_leaf' : range(1,40, 2),\n",
        "              'max_features'     : [None, 'auto', 'log2'] \n",
        "}\n",
        "\n",
        "classifier  = DecisionTreeClassifier(random_state = 0)\n",
        "\n",
        "grid_search = GridSearchCV(classifier, param_map, scoring = 'accuracy', cv= None) # By default it uses 5 fold validation\n",
        "grid_search.fit(X_todos_train, y_todos_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(best_model)\n",
        "\n",
        "best_model.fit(X_todos_train, y_todos_train)\n",
        "y_todos_pred = best_model.predict(X_todos_test)\n",
        "print_model_metrics(y_todos_test, y_todos_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=11, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=31, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=0, splitter='random')\n",
            "Accuracy 0.9\n",
            "Precision 0.7\n",
            "Recall 0.59\n",
            "f1_score 0.64\n",
            "[[616  30]\n",
            " [ 48  69]]\n",
            "\n",
            " True Negatives 616\n",
            "\n",
            " False Negatives 48\n",
            "\n",
            " True Positives 69\n",
            "\n",
            " False Positives 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aluM8f72AA5g"
      },
      "source": [
        "Prediccion para mujeres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaOEd_oC8Pn4",
        "outputId": "96491811-54c7-4b76-c7e8-228ad3d98374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Ahora hacemos el dataset de mujeres\n",
        "classifier   = SGDClassifier(random_state = 0)\n",
        "classifier.fit(X_mujeres_train, y_mujeres_train)\n",
        "y_mujeres_pred_train = classifier.predict(X_mujeres_train)\n",
        "y_mujeres_pred_test  = classifier.predict(X_mujeres_test)\n",
        "\n",
        "print('### Metricas de entrenamiento SDGC###')\n",
        "print_model_metrics(y_mujeres_train, y_mujeres_pred_train)\n",
        "print('\\n### Metricas de test SDGC ###')  \n",
        "print_model_metrics(y_mujeres_test, y_mujeres_pred_test)\n",
        "\n",
        "classifier   = DecisionTreeClassifier(random_state = 0)\n",
        "classifier.fit(X_mujeres_train, y_mujeres_train)\n",
        "y_mujeres_pred_train = classifier.predict(X_mujeres_train)\n",
        "y_mujeres_pred_test  = classifier.predict(X_mujeres_test)\n",
        "\n",
        "print('### Metricas de entrenamiento Tree ###\\n')\n",
        "print_model_metrics(y_mujeres_train, y_mujeres_pred_train)\n",
        "print('\\n### Metricas de test ### Tree \\n')\n",
        "print_model_metrics(y_mujeres_test, y_mujeres_pred_test)\n",
        "\n",
        "print(classifier.tree_.max_depth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### Metricas de entrenamiento SDGC###\n",
            "Accuracy 0.82\n",
            "Precision 0.26\n",
            "Recall 0.12\n",
            "f1_score 0.17\n",
            "[[1449   92]\n",
            " [ 234   33]]\n",
            "\n",
            " True Negatives 1449\n",
            "\n",
            " False Negatives 234\n",
            "\n",
            " True Positives 33\n",
            "\n",
            " False Positives 92\n",
            "\n",
            "### Metricas de test SDGC ###\n",
            "Accuracy 0.81\n",
            "Precision 0.22\n",
            "Recall 0.1\n",
            "f1_score 0.14\n",
            "[[360  25]\n",
            " [ 60   7]]\n",
            "\n",
            " True Negatives 360\n",
            "\n",
            " False Negatives 60\n",
            "\n",
            " True Positives 7\n",
            "\n",
            " False Positives 25\n",
            "### Metricas de entrenamiento Tree ###\n",
            "\n",
            "Accuracy 1.0\n",
            "Precision 1.0\n",
            "Recall 1.0\n",
            "f1_score 1.0\n",
            "[[1541    0]\n",
            " [   0  267]]\n",
            "\n",
            " True Negatives 1541\n",
            "\n",
            " False Negatives 0\n",
            "\n",
            " True Positives 267\n",
            "\n",
            " False Positives 0\n",
            "\n",
            "### Metricas de test ### Tree \n",
            "\n",
            "Accuracy 0.89\n",
            "Precision 0.65\n",
            "Recall 0.6\n",
            "f1_score 0.62\n",
            "[[363  22]\n",
            " [ 27  40]]\n",
            "\n",
            " True Negatives 363\n",
            "\n",
            " False Negatives 27\n",
            "\n",
            " True Positives 40\n",
            "\n",
            " False Positives 22\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWsHzNph8jMS",
        "outputId": "386c4e25-d7df-415f-d5e9-0b122f96f27f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Ahora buscamos el mejor modelo para el descenso por gradiente.\n",
        "param_map = { 'loss'          : ['hinge','log','squared_hinge'],\n",
        "              'penalty'       : ['l2','l1','elasticnet'],\n",
        "              'learning_rate' : ['optimal','adaptive','invscaling'],\n",
        "              'eta0'          : [0.1],\n",
        "              'max_iter'      : [20000,30000],\n",
        "              'alpha'         : [0.0001, 0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "classifier   = SGDClassifier(random_state = 0)\n",
        "\n",
        "grid_search = GridSearchCV(classifier, param_map, scoring = 'accuracy', cv= None) # By default it uses 5 fold validation)\n",
        "grid_search.fit(X_mujeres_train, y_mujeres_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(best_model)\n",
        "\n",
        "best_model.fit(X_mujeres_train, y_mujeres_train)\n",
        "y_mujeres_pred = best_model.predict(X_mujeres_test)\n",
        "print_model_metrics(y_mujeres_test, y_mujeres_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
            "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
            "              learning_rate='adaptive', loss='log', max_iter=20000,\n",
            "              n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
            "              random_state=0, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
            "              verbose=0, warm_start=False)\n",
            "Accuracy 0.91\n",
            "Precision 0.73\n",
            "Recall 0.6\n",
            "f1_score 0.66\n",
            "[[370  15]\n",
            " [ 27  40]]\n",
            "\n",
            " True Negatives 370\n",
            "\n",
            " False Negatives 27\n",
            "\n",
            " True Positives 40\n",
            "\n",
            " False Positives 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53q7oWrK81Mm",
        "outputId": "baf27619-b115-483d-ef2e-b1dcb03ebdd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "param_map = { 'criterion'        : ['gini','entropy'],\n",
        "              'splitter'         : ['best','random'],\n",
        "              'max_depth'        : list(range(2, 20, 1)) + [None],\n",
        "              'min_samples_leaf' : range(1,40, 2),\n",
        "              'max_features'     : [None, 'auto', 'log2'] \n",
        "}\n",
        "\n",
        "classifier  = DecisionTreeClassifier(random_state = 0)\n",
        "\n",
        "grid_search = GridSearchCV(classifier, param_map, scoring = 'accuracy', cv= None) # By default it uses 5 fold validation\n",
        "grid_search.fit(X_mujeres_train, y_mujeres_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(best_model)\n",
        "\n",
        "best_model.fit(X_mujeres_train, y_mujeres_train)\n",
        "y_mujeres_pred = best_model.predict(X_mujeres_test)\n",
        "print_model_metrics(y_mujeres_test, y_mujeres_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=11, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=13, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=0, splitter='random')\n",
            "Accuracy 0.9\n",
            "Precision 0.73\n",
            "Recall 0.54\n",
            "f1_score 0.62\n",
            "[[372  13]\n",
            " [ 31  36]]\n",
            "\n",
            " True Negatives 372\n",
            "\n",
            " False Negatives 31\n",
            "\n",
            " True Positives 36\n",
            "\n",
            " False Positives 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXmksKT1Bh3F"
      },
      "source": [
        "Prediccion para hombres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTzwWyUSCPGG",
        "outputId": "1a7e9742-901a-414c-d85d-9f86a7305a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Finalmente prediccion para hombres\n",
        "classifier   = SGDClassifier(random_state = 0)\n",
        "classifier.fit(X_hombres_train, y_hombres_train)\n",
        "y_hombres_pred_train = classifier.predict(X_hombres_train)\n",
        "y_hombres_pred_test  = classifier.predict(X_hombres_test)\n",
        "\n",
        "print('### Metricas de entrenamiento SDGC###')\n",
        "print_model_metrics(y_hombres_train, y_hombres_pred_train)\n",
        "print('\\n### Metricas de test SDGC ###')  \n",
        "print_model_metrics(y_hombres_test, y_hombres_pred_test)\n",
        "\n",
        "classifier   = DecisionTreeClassifier(random_state = 0)\n",
        "classifier.fit(X_hombres_train, y_hombres_train)\n",
        "y_hombres_pred_train = classifier.predict(X_hombres_train)\n",
        "y_hombres_pred_test  = classifier.predict(X_hombres_test)\n",
        "\n",
        "print('### Metricas de entrenamiento Tree ###\\n')\n",
        "print_model_metrics(y_hombres_train, y_hombres_pred_train)\n",
        "print('\\n### Metricas de test ### Tree \\n')\n",
        "print_model_metrics(y_hombres_test, y_hombres_pred_test)\n",
        "\n",
        "print(classifier.tree_.max_depth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "### Metricas de entrenamiento SDGC###\n",
            "Accuracy 0.84\n",
            "Precision 0.5\n",
            "Recall 0.26\n",
            "f1_score 0.34\n",
            "[[970  50]\n",
            " [144  51]]\n",
            "\n",
            " True Negatives 970\n",
            "\n",
            " False Negatives 144\n",
            "\n",
            " True Positives 51\n",
            "\n",
            " False Positives 50\n",
            "\n",
            "### Metricas de test SDGC ###\n",
            "Accuracy 0.81\n",
            "Precision 0.34\n",
            "Recall 0.22\n",
            "f1_score 0.27\n",
            "[[234  21]\n",
            " [ 38  11]]\n",
            "\n",
            " True Negatives 234\n",
            "\n",
            " False Negatives 38\n",
            "\n",
            " True Positives 11\n",
            "\n",
            " False Positives 21\n",
            "### Metricas de entrenamiento Tree ###\n",
            "\n",
            "Accuracy 1.0\n",
            "Precision 1.0\n",
            "Recall 1.0\n",
            "f1_score 1.0\n",
            "[[1020    0]\n",
            " [   0  195]]\n",
            "\n",
            " True Negatives 1020\n",
            "\n",
            " False Negatives 0\n",
            "\n",
            " True Positives 195\n",
            "\n",
            " False Positives 0\n",
            "\n",
            "### Metricas de test ### Tree \n",
            "\n",
            "Accuracy 0.88\n",
            "Precision 0.6\n",
            "Recall 0.67\n",
            "f1_score 0.63\n",
            "[[233  22]\n",
            " [ 16  33]]\n",
            "\n",
            " True Negatives 233\n",
            "\n",
            " False Negatives 16\n",
            "\n",
            " True Positives 33\n",
            "\n",
            " False Positives 22\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmOEoHIaCUyf",
        "outputId": "84075758-f1e1-4990-f1bb-84751b1f5697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Ahora buscamos el mejor modelo para el descenso por gradiente.\n",
        "param_map = { 'loss'          : ['hinge','log','squared_hinge'],\n",
        "              'penalty'       : ['l2','l1','elasticnet'],\n",
        "              'learning_rate' : ['optimal','adaptive','invscaling'],\n",
        "              'eta0'          : [0.1],\n",
        "              'max_iter'      : [20000,30000],\n",
        "              'alpha'         : [0.0001, 0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "classifier   = SGDClassifier(random_state = 0)\n",
        "\n",
        "grid_search = GridSearchCV(classifier, param_map, scoring = 'accuracy', cv= None) # By default it uses 5 fold validation)\n",
        "grid_search.fit(X_hombres_train, y_hombres_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(best_model)\n",
        "\n",
        "best_model.fit(X_hombres_train, y_hombres_train)\n",
        "y_hombres_pred = best_model.predict(X_hombres_test)\n",
        "print_model_metrics(y_hombres_test, y_hombres_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
            "              epsilon=0.1, eta0=0.1, fit_intercept=True, l1_ratio=0.15,\n",
            "              learning_rate='adaptive', loss='log', max_iter=20000,\n",
            "              n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
            "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
            "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "Accuracy 0.88\n",
            "Precision 0.63\n",
            "Recall 0.63\n",
            "f1_score 0.63\n",
            "[[237  18]\n",
            " [ 18  31]]\n",
            "\n",
            " True Negatives 237\n",
            "\n",
            " False Negatives 18\n",
            "\n",
            " True Positives 31\n",
            "\n",
            " False Positives 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8wfwn4qCkQe",
        "outputId": "d53be305-e63c-4aae-d9cb-df89b8a32827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "param_map = { 'criterion'        : ['gini','entropy'],\n",
        "              'splitter'         : ['best','random'],\n",
        "              'max_depth'        : list(range(2, 20, 1)) + [None],\n",
        "              'min_samples_leaf' : range(1,40, 2),\n",
        "              'max_features'     : [None, 'auto', 'log2'] \n",
        "}\n",
        "\n",
        "classifier  = DecisionTreeClassifier(random_state = 0)\n",
        "\n",
        "grid_search = GridSearchCV(classifier, param_map, scoring = 'accuracy', cv= None) # By default it uses 5 fold validation\n",
        "grid_search.fit(X_hombres_train, y_hombres_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(best_model)\n",
        "\n",
        "best_model.fit(X_hombres_train, y_hombres_train)\n",
        "y_hombres_pred = best_model.predict(X_hombres_test)\n",
        "print_model_metrics(y_hombres_test, y_hombres_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=17, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=0, splitter='best')\n",
            "Accuracy 0.9\n",
            "Precision 0.67\n",
            "Recall 0.73\n",
            "f1_score 0.7\n",
            "[[237  18]\n",
            " [ 13  36]]\n",
            "\n",
            " True Negatives 237\n",
            "\n",
            " False Negatives 13\n",
            "\n",
            " True Positives 36\n",
            "\n",
            " False Positives 18\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}